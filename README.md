# üìà Modelos de Trading: la b√∫squeda esquiva de la rentabilidad constante

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Machine Learning](https://img.shields.io/badge/Machine%20Learning-Scikit--Learn-orange)
![Status](https://img.shields.io/badge/Status-Completed-brightgreen)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

---

## üß† 1. Introducci√≥n

¬øAlguna vez te has preguntado c√≥mo convertir datos brutos de trading en una ventaja operativa real?

Este proyecto naci√≥ de esa inquietud: transformar un simple registro hist√≥rico de operaciones en una **fuente de informaci√≥n estrat√©gica**.

El objetivo fue **optimizar los resultados de un modelo de trading**, analizando los datos hist√≥ricos de *Take Profit* y *Stop Loss* para **aumentar el Win Rate y mejorar la relaci√≥n riesgo-beneficio**.

---

## üßπ 2. Limpieza y preparaci√≥n de datos

Antes de cualquier optimizaci√≥n, el primer paso fue una **limpieza y preparaci√≥n exhaustiva** del dataset.

### Tareas realizadas:
- Eliminaci√≥n de filas con valores faltantes en `ticks_SL` (Stop Loss en ticks), ya que representaban registros incompletos.  
- Conversi√≥n de tipos de datos para garantizar que las columnas num√©ricas fueran correctamente interpretadas.  
- Creaci√≥n de una columna `fecha` (a√±o, mes y d√≠a) y uso de esta para completar los valores faltantes de `dia_semana`.  
- Eliminaci√≥n de columnas irrelevantes o con exceso de valores nulos (`HIN`, `hora_HIN`).  

### M√©tricas iniciales (dataset sin optimizar):

| M√©trica | Valor |
| --- | --- |
| Win Rate inicial | **31.85%** |
| M√°xima racha de p√©rdidas | **16** |
| RR promedio en operaciones ganadoras | **3.50** |
| Profit factor | **1.89** |

> Este punto de partida permiti√≥ visualizar el desempe√±o base del sistema antes de aplicar mejoras.

---

## üîç 3. An√°lisis Exploratorio de Datos (EDA)

El **EDA (Exploratory Data Analysis)** permiti√≥ identificar las variables con mayor impacto en los resultados.

Se analizaron dos factores principales:
- `ticks_rango_OTE`: tama√±o de la zona de entrada √≥ptima (en ticks).  
- `antiguedad_de_liquidez`: tiempo transcurrido desde que se form√≥ la liquidez.

### Hallazgos clave:
- Operaciones con `ticks_rango_OTE` > **55.2** mostraban una **disminuci√≥n significativa en el Win Rate**.  
- Operaciones con `antiguedad_de_liquidez` > **300** velas tambi√©n ten√≠an **menor probabilidad de √©xito**.

üìä **Conclusi√≥n:**  
Filtrar operaciones con valores superiores a estos umbrales mejora las m√©tricas generales del sistema.

---

## ‚öôÔ∏è 4. Resultados tras el filtrado

Despu√©s de aplicar los filtros (`ticks_rango_OTE ‚â§ 55.2` y `antiguedad_de_liquidez ‚â§ 300`), los resultados mejoraron notablemente:

| M√©trica | Antes del filtro | Despu√©s del filtro |
| --- | --- | --- |
| Win Rate | 31.85% | **34.88%** |
| M√°x. racha de p√©rdidas | 16 | **13** |
| RR promedio (TPs) | 3.50 | **3.55** |

> Este filtrado elimin√≥ setups hist√≥ricamente desfavorables, aumentando la consistencia general del modelo.  
> Pero esperen, esta optimizaci√≥n reci√©n comienza...

---

## üéØ 5. Optimizaci√≥n del Take Profit (TP)

Se aplic√≥ una estrategia de **optimizaci√≥n din√°mica del Take Profit** en funci√≥n del tama√±o de la zona OTE (`ticks_rango_OTE`).

### Objetivo:
Maximizar el valor esperado para cada operaci√≥n:

\[
E(R) = R \times P(\text{alcanzar R sin Stop Loss})
\]

Mediante an√°lisis de percentiles de `RR_potencial` y simulaciones, se estim√≥ un TP √≥ptimo para cada intervalo de OTE.

### Resultados:

| M√©trica | Valor |
| --- | --- |
| R:R total (datos filtrados originales) | 126.53 |
| R:R total (con TP optimizado) | **236.57** |
| Mejora absoluta | **+110.04** |
| Mejora porcentual | **+86.9%** |

üìà **Conclusi√≥n:**  
Definir din√°micamente el TP en base a las caracter√≠sticas del trade casi duplic√≥ la rentabilidad total.

---

## üß± 6. Ajuste del Stop Loss (SL)

Se analiz√≥ el efecto del **retroceso m√°ximo del precio dentro del OTE** (`profundidad_retroceso_real`).

- Cuando el precio retroced√≠a **0.9 del rango OTE**, la mayor√≠a de las operaciones terminaban en p√©rdida.  
- Se implement√≥ una estrategia ajustada:
  - Si el retroceso llegaba a 0.9 ‚Üí se consideraba Stop Loss anticipado (-1R).  
  - Si la operaci√≥n alcanzaba TP sin retroceder a 0.9 ‚Üí se ajustaba su R:R hacia arriba (x1.33).  

### Resultados:

| M√©trica | Valor |
| --- | --- |
| R:R total (original filtrado) | 126.53 |
| R:R total (con SL ajustado a 0.9) | **163.00** |
| Mejora absoluta | **+36.47** |
| Mejora porcentual | **+28.82%** |

üìâ **Conclusi√≥n:**  
Incorporar un Stop Loss din√°mico basado en retroceso aument√≥ significativamente la eficiencia operativa.

---

## ‚öñÔ∏è 7. Impacto combinado (TP + SL)

La combinaci√≥n de ambas estrategias produjo los mejores resultados globales.

| Criterio | Win Rate (%) | Prom. RR (ganadoras) | Profit Factor | M√°x. racha p√©rdidas |
| --- | --- | --- | --- | --- |
| RR_real (sin cambios) | 34.42 | 3.615 | 1.897 | 13 |
| RR_real con 0.9 SL | 30.23 | 4.815 | 2.087 | 15 |
| TP √≥ptimo | 22.53 | 9.209 | 2.678 | 13 |
| TP √≥ptimo + SL 0.9 | **20.88** | **12.016** | **3.149** | **13** |

üìä **Conclusi√≥n:**  
Aunque el Win Rate baj√≥ ligeramente, el **Profit Factor casi se duplic√≥ (de 1.89 a 3.1)** y la rentabilidad acumulada aument√≥ dr√°sticamente.

---

## ü§ñ 8. Predicci√≥n con Machine Learning

Finalmente, se desarroll√≥ un modelo de **clasificaci√≥n supervisada** para predecir el resultado de una operaci√≥n (TP o SL).

### Preparaci√≥n de datos:
- Eliminaci√≥n de variables *spoiler* (como `RR_real`).  
- Imputaci√≥n de valores faltantes.  
- Estandarizaci√≥n (`StandardScaler`) y codificaci√≥n categ√≥rica (`OneHotEncoder`).  
- Divisi√≥n *train/test* y evaluaci√≥n con `SMOTE` para manejar desbalanceo.

### Modelos entrenados:
`Logistic Regression ¬∑ Random Forest ¬∑ Gradient Boosting ¬∑ SVM ¬∑ KNN ¬∑ Decision Tree ¬∑ Naive Bayes (ajustado) ¬∑ MLP Classifier ¬∑ LightGBM ¬∑ XGBoost`

### M√©tricas del modelo Naive Bayes (mejor resultado):

| M√©trica | Valor |
| --- | --- |
| AUC | 0.7039 |
| Precisi√≥n (TP) | 0.346 |
| Recall (TP) | **0.947** |
| F1-Score (TP) | 0.507 |
| Accuracy global | 0.4068 |

üìà **Interpretaci√≥n:**  
El modelo tiene un **recall del 95% para identificar trades ganadores**, lo que significa que detecta casi todos los Take Profits reales, aunque con cierta sobrepredicci√≥n ‚Äî justo lo que buscamos: **no dejar pasar operaciones rentables**, incluso a costa de algunos falsos positivos.

---

## üìä 9. Conclusiones generales

### Principales mejoras obtenidas:

| Aspecto | Antes | Modelo mejorado sin ML |
| --- | --- | --- |
| Win Rate | 34% | **20.88%** |
| Profit Factor | 1.89 | **3.14** |
| Recall (TP, modelo ML) | ‚Äî | **0.95** |

### Insights clave:
- El filtrado basado en EDA elimin√≥ contextos poco rentables.  
- La optimizaci√≥n del TP y el ajuste del SL transformaron la curva de rendimiento.  
- El Win Rate baj√≥ ligeramente, pero el *profit factor* se dispar√≥, gracias a operaciones con mayores recompensas.  
- El modelo Naive Bayes demostr√≥ un gran potencial como filtro predictivo de operaciones, anticipando setups ganadores en tiempo real.

---

## üîÆ 10. Pr√≥ximos pasos

1. **Integrar el clasificador Naive Bayes** al proceso operativo para filtrar setups de alta probabilidad.  
2. **Refinar el modelo de regresi√≥n** para estimar mejor el `RR_potencial`.  
3. **Agregar nuevas fuentes de datos**, como volatilidad o sentimiento de mercado.  
4. **Backtesting completo** con las reglas y modelos combinados para validar robustez y estabilidad.

---

## üß≠ Conclusi√≥n final

Este proyecto demuestra c√≥mo una estrategia de trading puede **evolucionar de una intuici√≥n a un sistema basado en datos**, combinando an√°lisis exploratorio, optimizaci√≥n estad√≠stica y modelos predictivos.

**Resultado:**  
> De un *Profit Factor* de **1.3 a m√°s de 3.0**, con un enfoque replicable, medible y sustentado en evidencia.

---

### üß∞ Stack Tecnol√≥gico

| √Årea | Herramientas |
|------|---------------|
| Lenguaje | Python (3.10+) |
| An√°lisis | Pandas, NumPy, Seaborn, Matplotlib |
| Modelado | Scikit-learn, LightGBM, XGBoost |
| Optimizaci√≥n | GridSearchCV, Interpolaci√≥n de percentiles |
| ML Pipeline | Imputer + Scaler + OneHotEncoder + Classifier |
| Entorno | Google Colab / Jupyter Notebook |

---

### üì¨ Contacto

**Autor:** Valent√≠n √Ålvarez Lamas  
**Email:** [valentinalvarezlamas@gmail.com](mailto:valentinalvarezlamas@gmail.com)  
**LinkedIn:** [linkedin.com/in/valentinalvarezlamas](https://www.linkedin.com/in/valentinalvarezlamas)

---
